{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuLfg3jq5WBb8s0I7/EyFy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacquelinedoan/pricing_causal/blob/main/pricing_causal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Heckman Correction, Instrumental Variable, and DoubleML for Demand Modelling with Censored Purchase Data**"
      ],
      "metadata": {
        "id": "XofD2e_LL3F1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a given customer $i$ and product $j$ (and context $x$), we want price $p^*$ such that\n",
        "$$p^* = \\text{argmax}_p \\text{ profit} (p|x) = (p-c)\\times E(D(p|x))$$\n",
        "\n",
        "where\n",
        "*   $c$: unit cost\n",
        "*   $D(p|x)$: expected demand at price $p$ given context $x$"
      ],
      "metadata": {
        "id": "Fpxx8RcDL1BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install doubleml"
      ],
      "metadata": {
        "id": "Ebra6n_4vvW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "sGLKfQBd_NnK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Data\n",
        "\n",
        "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
        "cust, sell, rev, item, prod, geo, cat, orders, pay = [pd.read_csv(f\"{path}/{file}\") for file in os.listdir(path)]\n",
        "master = orders.merge(cust, on=\"customer_id\", how='left')\\\n",
        "               .merge(item, on=\"order_id\", how='left')\\\n",
        "               .merge(prod, on=\"product_id\", how='left')\\\n",
        "               .merge(cat, on=\"product_category_name\", how='left')\\\n",
        "               .merge(sell, on=\"seller_id\", how='left')\\\n",
        "               .merge(pay, on=\"order_id\", how='left')\\\n",
        "               .merge(rev, on=\"order_id\", how='left')\n",
        "\n",
        "# Drop entries where price is null\n",
        "master.dropna(subset=['price'], inplace=True)\n",
        "master.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Handle Datetime data\n",
        "master['order_purchase_timestamp'] = pd.to_datetime(master.order_purchase_timestamp,\n",
        "                                             format='%Y-%m-%d %H:%M:%S')\n",
        "master['order_estimated_delivery_date'] = pd.to_datetime(master.order_estimated_delivery_date,\n",
        "                                              format='%Y-%m-%d %H:%M:%S')\n",
        "master['days_to_delivery'] = (master.order_estimated_delivery_date - master.order_purchase_timestamp).dt.days\n",
        "\n",
        "master['order_purchase_weekday'] = master['order_purchase_timestamp'].dt.day_name()\n",
        "\n",
        "# Selection Indicator\n",
        "master['S'] = (master['order_status'] != 'canceled').astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(master.shape)\n",
        "display(master.order_status.value_counts())\n",
        "# Assumptions:\n",
        "# As long as the status is not cancelled, we assume the customer completed the purchase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "PddGb9_NizVw",
        "outputId": "6bcdc5bb-6f5b-4bfb-cba4-462463e3c8dd"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(118310, 43)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "order_status\n",
              "delivered      115723\n",
              "shipped          1255\n",
              "canceled          570\n",
              "invoiced          376\n",
              "processing        376\n",
              "unavailable         7\n",
              "approved            3\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_status</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>delivered</th>\n",
              "      <td>115723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shipped</th>\n",
              "      <td>1255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>canceled</th>\n",
              "      <td>570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>invoiced</th>\n",
              "      <td>376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>processing</th>\n",
              "      <td>376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unavailable</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>approved</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Null Treatment\n",
        "# Categorical\n",
        "master.select_dtypes(include=['object']).fillna('Unknown', inplace=True)\n",
        "# Numerical\n",
        "master.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "1lNKv2_PPo8z"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Set-Up**:\n",
        "\n",
        "\n",
        "1.   Endogenous Variable: price is partially determined by demand. **Need Instrumental Variable.**\n",
        "\n",
        "2.   Censored Data: decision to not purchase is not observable. **Need Selection Correction.**"
      ],
      "metadata": {
        "id": "yotTeT5IGT-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic pricing requires a demand model/ demand curve. A demand curve is the relationship between the quantity demanded (or propensity to purchase) and the price among other features.\n"
      ],
      "metadata": {
        "id": "speAjM6oBXiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instrumental Variable\n",
        "We want to estimate the response of market demand to exogenous changes in market prices. Quantity demanded depends on prices, but prices are not exogenously given since they are determined in part by market demand. The instrument for price is a variable that is correlated with price but does not directly effect quantity demanded, ideally a supply-inducing variable.\n",
        "\n",
        "**IV ($Z$) Requirements**\n",
        "1.   **Relevance**: $\\text{Cov}(Z,\\text{price}) \\neq 0$\n",
        "2.   **Exclusion/ Validity**: $Z \\perp ϵ$ where $ϵ$ unobserved demand shock.\n",
        "\n",
        "Some candidates:\n",
        "\n",
        "\n",
        "*   Supply-side shock: supplier cost change, wholesale price, shipping cost (shift retail price but doesn't directly affect demand)\n",
        "*   Day-of-week, temporary promotions (only if random scheduling)\n",
        "* Regional difference: warehouse stock levels, local supply constraints (only if no difference in preference across regions)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aAVUurMmNyxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Possible Instrumental Variables\n",
        "iv = [\n",
        "    'order_purchase_weekday', # day of the week\n",
        "    'freight_value', # shipping cost\n",
        "    'seller_state', # proxy for regional supply shock\n",
        "     ]"
      ],
      "metadata": {
        "id": "gHXpOuqAHSo7"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price = ['price']\n",
        "\n",
        "covariates = [\n",
        "       'days_to_delivery',\n",
        "       'customer_zip_code_prefix',\n",
        "      #  'customer_city',\n",
        "       'customer_state',\n",
        "       'product_category_name',\n",
        "       'product_name_lenght',\n",
        "       'product_description_lenght',\n",
        "       'product_photos_qty',\n",
        "       'product_weight_g',\n",
        "       'product_length_cm',\n",
        "       'product_height_cm',\n",
        "       'product_width_cm',\n",
        "       'seller_zip_code_prefix',\n",
        "      #  'seller_city',\n",
        "       'seller_state',\n",
        "       'payment_sequential',\n",
        "       'payment_type',\n",
        "       'payment_installments',\n",
        "       'payment_value',\n",
        "       'review_score',\n",
        "       ]"
      ],
      "metadata": {
        "id": "bzhL32V2KsLP"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Empirical Check for Relevance\n",
        "X = master[covariates]\n",
        "Z = master[iv]\n",
        "y = master[price]"
      ],
      "metadata": {
        "id": "yZj4kTFjChR3"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XZ = sm.add_constant(pd.concat([X, Z], axis=1))"
      ],
      "metadata": {
        "id": "xIRtx-ogNKuU"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Empirical Check for Relevance\n",
        "import statsmodels.api as sm\n",
        "\n",
        "XZ = sm.add_constant(pd.concat([X, Z], axis=1))\n",
        "\n",
        "# One-hot encode categorical columns in XZ\n",
        "XZ_encoded = pd.get_dummies(XZ, columns= XZ.select_dtypes(include=['object']).columns,\n",
        "                            dummy_na=False)"
      ],
      "metadata": {
        "id": "fkVdcCxAMPSu"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An overview look of the IV. F Statistic is > 10, the instruments chosen are strong\n",
        "relevance = sm.OLS(y, XZ_encoded.astype(float)).fit()\n",
        "print(relevance.fvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CULKmimMR7T",
        "outputId": "fe27199f-c6a0-43b0-e06c-ec57d479e800"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1372.4823046484248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Conditional Regressions (Sanderson-Windmeijer, 2016)\n",
        "# # We have strong instruments\n",
        "# X = master[covariates]\n",
        "# Z = master[iv]\n",
        "# y = master[price]\n",
        "\n",
        "# Z_encoded = pd.get_dummies(Z,\n",
        "#                             columns=Z.select_dtypes(include=['object']).columns,\n",
        "#                             dummy_na=False)\n",
        "# X_encoded = pd.get_dummies(X,\n",
        "#                             columns=X.select_dtypes(include=['object']).columns,\n",
        "#                             dummy_na=False)\n",
        "\n",
        "# for z in Z_encoded.columns:\n",
        "#     print(f\"Conditional Regression for {z}:\")\n",
        "#     other_Z = Z_encoded.drop(columns=[z])\n",
        "#     XZ_other = sm.add_constant(pd.concat([X_encoded, other_Z], axis=1))\n",
        "#     # y = master[price]\n",
        "#     y=Z_encoded[z]\n",
        "#     model = sm.OLS(y, XZ_other.astype(float)).fit()\n",
        "\n",
        "#     f_stat = model.fvalue\n",
        "#     p_val = model.f_pvalue\n",
        "\n",
        "#     print(f\"Conditional F-test for {z}: F={f_stat:.2f}, p={p_val:.4f}\")"
      ],
      "metadata": {
        "id": "F6Xf35sZUeTR"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heckman Correction\n",
        "\n",
        "*   **Definition** (Selection Equation): The individual sampling probability of each observation\n",
        "*   **Definition** (Outcome Equation): The conditional expectation of the dependent variable\n",
        "\n",
        "**Two Stages of Heckman Correction**\n",
        "1.   Estimate the probability of purchase. Here, we will use XGBoost to estimate\n",
        "$$\\hat{p}_i = P(S_i =1|z_i)$$\n",
        "where $S_i=1$ means the purchase is observed and $z_i$ are instruments/ exclusion variables, affecting selection, but not directly purchase outcome.\n",
        "2.   Correct for self-selection by incorporating a transformation of these predicted individual probabilities as an explanatory variable. This is done by computing the **inverse Mills ratio** for each observation $i$\n",
        "$$\\lambda_i = \\frac{\\phi(\\Phi^{-1}(\\hat{p}_i))}{\\hat{p}_i}$$\n",
        "and use the ratio as a control in outcome regression.\n"
      ],
      "metadata": {
        "id": "MU9LSBACepTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import norm"
      ],
      "metadata": {
        "id": "m3HmRm2_NwpI"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = master[covariates]\n",
        "Z = master[iv]\n",
        "y = master[price].values"
      ],
      "metadata": {
        "id": "BemLcIgbNwi1"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selection Model\n",
        "X_selection = master[covariates+iv]\n",
        "y_selection = master['S']\n",
        "\n",
        "# XGBoost classifier for selection\n",
        "ml_selector = XGBClassifier(eval_metric='logloss',\n",
        "                            )\n",
        "\n",
        "# Perform one-hot encoding on X_selection\n",
        "X_selection_encoded = pd.get_dummies(X_selection,\n",
        "                                     columns=X_selection.select_dtypes(include='object').columns,\n",
        "                                     dummy_na=False)\n",
        "\n",
        "ml_selector.fit(np.array(X_selection_encoded), np.array(y_selection))\n",
        "# Predict selection probability per observation\n",
        "p_hat = ml_selector.predict_proba(np.array(X_selection_encoded))[:, 1]\n",
        "# Compute IMR (inverse Mills ratio) for Heckman-style correction\n",
        "imr = norm.pdf(norm.ppf(np.clip(p_hat, 1e-6, 1-1e-6))) / np.clip(p_hat, 1e-6, 1-1e-6)\n",
        "master['imr'] = imr"
      ],
      "metadata": {
        "id": "i5mnpMuEKLkZ"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outcome model\n",
        "from doubleml import DoubleMLData, DoubleMLPLR\n",
        "\n",
        "X_outcome = master[covariates+['imr', 'S', 'price']]\n",
        "\n",
        "# One-hot encode categorical columns in XZ\n",
        "X_outcome_encoded = pd.get_dummies(\n",
        "                          X_outcome,\n",
        "                          columns=X_outcome.select_dtypes(include=['object']).columns,\n",
        "                          dummy_na=False)\n",
        "\n",
        "dml_data = DoubleMLData(data=X_outcome_encoded[X_outcome_encoded.S==1],\n",
        "                        y_col='S', # outcome\n",
        "                        d_cols='price', # treatment\n",
        "                        x_cols= X_outcome_encoded.drop(columns=['S', 'price']).columns.tolist(), # covariates\n",
        "                        )\n",
        "\n",
        "# Double ML\n",
        "ml_l = XGBRegressor(n_estimators=100, max_depth=3)\n",
        "ml_m = XGBRegressor(n_estimators=100, max_depth=3)\n",
        "\n",
        "dml_plr = DoubleMLPLR(dml_data, ml_l=ml_l, ml_m=ml_m)\n",
        "dml_plr.fit()\n",
        "\n",
        "# Treatment effect estimate\n",
        "print(\"Theta_hat:\", dml_plr.coef)\n",
        "print(\"Std. Error:\", dml_plr.se)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5saTCHutGVj",
        "outputId": "28d6e447-65ad-43f7-ec09-56685dc3ef7b"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta_hat: [0.]\n",
            "Std. Error: [0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/doubleml/utils/_sensitivity.py:6: RuntimeWarning: invalid value encountered in divide\n",
            "  psi_max_bias = np.divide(np.add(np.multiply(sigma2, psi_nu2), np.multiply(nu2, psi_sigma2)), np.multiply(2.0, max_bias))\n"
          ]
        }
      ]
    }
  ]
}